{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why JAX?\n",
    "\n",
    "!!! Info \"\"\n",
    "    If you are interested in Feedbax but unfamiliar with JAX—or new to Python—then read on, for an overview of some of the tools on which Feedbax is based.\n",
    "\n",
    "JAX isn't a machine learning framework like [PyTorch](https://pytorch.org/). It's a more general-purpose tool. \n",
    "\n",
    "??? Info \"What does JAX provide?\"\n",
    "\n",
    "    - A [NumPy](https://numpy.org/)-like API: Many of the things you can write in NumPy, you [can also write](https://jax.readthedocs.io/en/latest/jax.numpy.html) in JAX—you just have to `import jax.numpy as jnp` instead of `import numpy as np`. \n",
    "    - [Just-in-time (JIT) compilation](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html): In many cases, this makes JAX much faster than NumPy. \n",
    "    - [Automatic differentiation](https://jax.readthedocs.io/en/latest/jax-101/01-jax-basics.html#jax-first-transformation-grad): We use this to get derivatives of functions—usually, to train models through gradient descent.\n",
    "    - [Automatic vectorization](https://jax.readthedocs.io/en/latest/jax-101/03-vectorization.html): We can easily transform a function that works on single examples, to a function that processes entire batches of data.\n",
    "    - [Parallelism](https://jax.readthedocs.io/en/latest/jax-101/06-parallelism.html): This makes it easy to split up a large model across multiple devices (e.g. GPUs).\n",
    "\n",
    "    Automatic differention and JIT compilation are features normally found working in the background in ML frameworks, but JAX lets you use them in explicit, arbitrary, powerful ways.\n",
    "\n",
    "\n",
    "That's why Feedbax is not just built on JAX, but also:\n",
    "\n",
    "- [Equinox](https://github.com/patrick-kidger/equinox), which allows us to define PyTorch-like modules, making it easiers to organize our models;\n",
    "- [Optax](https://github.com/google-deepmind/optax), which provides optimizers (like Adam) which you'd normally find in ML frameworks;\n",
    "- [Diffrax](https://github.com/patrick-kidger/diffrax), which provides numerical solvers for differential equations.\n",
    "\n",
    "My favourite part about working with JAX is how nicely it plays with nested containers of data, or [*PyTrees*](https://jax.readthedocs.io/en/latest/pytrees.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytrees\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a list and a dict that contain similar values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_list = [1, 2, 3]\n",
    "\n",
    "some_dict = {'a': 1, 'b': 2, 'c': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In standard Python, a [*comprehension*](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) is a typical way of applying some computation to every value in a list or dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x ** 2 for x in some_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 4, 'c': 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: x ** 2 for k, x in some_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these solutions are similar, they're not interchangeable. If our data is a list we can use the first method and get a list in return. But as soon as we start using some data that's stored in a dict, we need to change our code.\n",
    "\n",
    "Conveniently, JAX provides a function [`tree_map`](https://jax.readthedocs.io/en/latest/_autosummary/jax.tree_util.tree_map.html) that behaves the same way for both lists and dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax.tree_util import tree_map\n",
    "\n",
    "tree_map(lambda x: x ** 2, some_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 4, 'c': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_map(lambda x: x ** 2, some_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??? Note \"Python's built-in `map`\"\n",
    "    Python includes a built-in function [`map`](https://docs.python.org/3/library/functions.html#map) which is similar in principle to `tree_map`. For example, we can do `list(map(lambda x: x**2, some_list))` to get the same result as `tree_map(lambda x: x**2, some_list)`. \n",
    "    \n",
    "    However, `map` doesn't return the same data structure it is given: to square all the values in a dict, and return a dict like we did with `tree_map`, we'd have to do something like `dict(zip(some_dict.keys(), map(lambda x: x**2, some_dict.values())))`. This is harder to read, and write.\n",
    "\n",
    "\n",
    "Even better, `tree_map` works on nested containers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA backend failed to initialize: Unable to load CUDA. Is it installed? (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'p': [1, 4], 'x': 1.0},\n",
       " [25, 36, 49, 64, {'y': Array([4, 4, 4], dtype=int32)}]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "some_data = [{'p': [1, 2], 'x': 1.0},\n",
    "             [5, 6, 7, 8, {'y': jnp.array([2, 2, 2])}]]\n",
    "\n",
    "tree_map(lambda x: x ** 2, some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this work? JAX treats both lists and dicts—*and any nested structures of lists and dicts*—as PyTrees. \n",
    "\n",
    "A PyTree's *leaves* are the data it ultimately contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1.0, 5, 6, 7, 8, Array([2, 2, 2], dtype=int32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax.tree_util import tree_leaves, tree_structure\n",
    "\n",
    "tree_leaves(some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those leaves are arranged in a tree with a certain structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyTreeDef([{'p': [*, *], 'x': *}, [*, *, *, *, {'y': *}]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_structure(some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the JAX array counts as a leaf, not as part of the tree structure. What does JAX treat as a leaf, and what does it treat as the structure in which all the leaves are contained? \n",
    "\n",
    "By default:\n",
    "\n",
    "- *leaves*—AKA *leaf nodes*—include NumPy and JAX arrays, as well as basic data types like `int`, `float`, `str`, and `bool`;\n",
    "- *internal nodes* are lists, dicts, and tuples, which JAX recognizes as PyTrees themselves. When JAX encounters these, its default stance is that \"nesting continues here\"—so it looks inside the node for leaves, or even deeper layers of nodes.\n",
    "\n",
    "Importantly, we can change what counts as a leaf. Many functions that operate on PyTrees can take an argument `is_leaf`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'p': [1, 2], 'x': 1.0}, 5, 6, 7, 8, {'y': Array([2, 2, 2], dtype=int32)}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_leaves(some_data, is_leaf=lambda x: isinstance(x, dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyTreeDef([*, [*, *, *, *, *]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_structure(some_data, is_leaf=lambda x: isinstance(x, dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've told JAX to treat dicts as leaves, rather than as containers. Now, the dicts appear whole and unflattened in the list of leaves, and the PyTree structure reflects this. \n",
    "\n",
    "To get the leaves and the tree structure in one call, use [`tree_flatten`](https://jax.readthedocs.io/en/latest/_autosummary/jax.tree_util.tree_flatten.html#jax.tree_util.tree_flatten):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import tree_flatten\n",
    "\n",
    "leaves, structure = tree_flatten(some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given both leaves and the structure, [`tree_unflatten`](https://jax.readthedocs.io/en/latest/_autosummary/jax.tree_util.tree_unflatten.html#jax.tree_util.tree_unflatten) builds a PyTree. Let's reconstruct the original `some_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import tree_unflatten\n",
    "\n",
    "tree_unflatten(structure, leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because JAX understands the structure of PyTrees, we can apply operations to multiple PyTrees when their structures match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_arrays = [\n",
    "    (jnp.array([1, 2]), jnp.array([3, 4])),\n",
    "    jnp.array([5, 6])\n",
    "]\n",
    "\n",
    "some_other_arrays = [\n",
    "    (jnp.array([7, 8]), jnp.array([3, 4])),\n",
    "    jnp.array([1, 1])\n",
    "]\n",
    "\n",
    "tree_structure(some_arrays) == tree_structure(some_other_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Array([ 8, 10], dtype=int32), Array([6, 8], dtype=int32)),\n",
       " Array([6, 7], dtype=int32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_map(\n",
    "    lambda x, y: x + y,\n",
    "    some_arrays,\n",
    "    some_other_arrays\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `tree_map` works \"leafwise\" to pick out the arguments to a function: the `x` values are the leaves from `some_arrays`, and the `y` values are the matching leaves from `some_other_arrays`. \n",
    "\n",
    "In this example, the result will be different if we tell JAX to treat tuples as leaves. The first two JAX arrays in each PyTree are contained in a tuple, so the first `x` passed to the function will be a pair of tuples, as will the first `y`. When we apply `+` to two tuples, we concatenate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Array([1, 2], dtype=int32),\n",
       "  Array([3, 4], dtype=int32),\n",
       "  Array([7, 8], dtype=int32),\n",
       "  Array([3, 4], dtype=int32)),\n",
       " Array([6, 7], dtype=int32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_map(\n",
    "    lambda x, y: x + y,\n",
    "    some_arrays,\n",
    "    some_other_arrays,\n",
    "    is_leaf=lambda x: isinstance(x, tuple)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array that's not inside a tuple gets added the same way it did before, because it still counts as a leaf—it's just that now, tuples *also* count as leaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A pytree of your own\n",
    "\n",
    "A PyTree is any kind of container that JAX knows how to flatten and unflatten. By default, this includes lists, dicts, and tuples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the default containers aren't enough for us, we can define our own types of containers, and tell JAX how to flatten and unflatten them. After that, JAX will treat them as PyTrees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.tree_util import register_pytree_node_class\n",
    "\n",
    "@register_pytree_node_class\n",
    "class TwoValues:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def tree_flatten(self):\n",
    "        return (self.a, self.b), None  # leaves, aux_data\n",
    "\n",
    "    @classmethod\n",
    "    def tree_unflatten(cls, aux_data, leaves):\n",
    "        print(aux_data)\n",
    "        return cls(*leaves)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the method `tree_flatten` tells JAX how to flatten a `TwoValues` object into its leaves, and `tree_unflatten` tells how to construct `TwoValues` given the leaves.\n",
    "\n",
    "As its name suggests, the decorator [`register_pytree_node_class`](https://jax.readthedocs.io/en/latest/_autosummary/jax.tree_util.register_pytree_node_class.html#jax.tree_util.register_pytree_node_class) registers our new PyTree type with JAX.\n",
    "\n",
    "Now we can use `TwoValues` as part of any PyTree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 45, 3, 4, 5]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = (TwoValues(12, 45), 3, {'a': TwoValues(4, 5)})\n",
    "\n",
    "tree_leaves(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyTreeDef((CustomNode(TwoValues[None], [*, *]), *, {'a': CustomNode(TwoValues[None], [*, *])}))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_structure(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equinox\n",
    "\n",
    "!!! Note inline end \"\"\n",
    "    Most objects in Feedbax are derived from `equinox.Module`.\n",
    "\n",
    "[Equinox](https://docs.kidger.site/equinox/) adds some useful tools to JAX. \n",
    "\n",
    "In particular, [`equinox.Module`](https://docs.kidger.site/equinox/api/module/module/) allows us to easily define classes that are PyTrees, and that combine model parameters with model computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "\n",
    "\n",
    "class SomeModel(eqx.Module):\n",
    "    param1: int\n",
    "    param2: jax.Array\n",
    "\n",
    "    def __call__(self, x: float):\n",
    "        return self.param1 + x * self.param2\n",
    "\n",
    "\n",
    "# Construct an example model.\n",
    "model = SomeModel(3, jnp.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our class definition, the method `__call__` tells Python how a `SomeModel` object should behave, when we call it like a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a nice way to define and execute our model computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Another convenient thing about Equinox `Module` is that it's a [`dataclass`](https://docs.python.org/3/library/dataclasses.html). In a normal Python class, to assign `param1` and `param2` as instance attributes we'd have to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeModel:\n",
    "    def __init__(self, param1: int, param2: jax.Array):\n",
    "        self.param1 = param1\n",
    "        self.param2 = param2\n",
    "\n",
    "    def __call__(self, x: float):\n",
    "        return self.param1 + x * self.param2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When our class is a dataclass, it automatically defines a default `__init__` method like the one above. We just have to define the list of parameters (that is, dataclass *fields*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SomeModel:\n",
    "    param1: int\n",
    "    param2: jax.Array\n",
    "\n",
    "    def __call__(self, x: float):\n",
    "        return self.param1 + x * self.param2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any class or subclass we define from `eqx.Module` will automatically work this way, without needing to add the `@dataclass` decorator. \n",
    "\n",
    "!!! Note \n",
    "    We can still add our own `__init__` method to a dataclass if we need to do something fancier than just assigning values to fields. \n",
    "    \n",
    "    In case only small modifications to `__init__` are needed, it may be convenient to define [`__post_init__`](https://docs.python.org/3/library/dataclasses.html#dataclasses.__post_init__) instead.\n",
    "\n",
    "The best thing about Equinox modules is that they are PyTrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, Array([1, 2, 3], dtype=int32)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a flattened list of model parameters.\n",
    "tree_leaves(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out this is very useful for structuring models, but that's beyond the scope of this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "??? Note \"Similarity of Equinox and PyTorch modules\"\n",
    "    Equinox's [`Module`](https://docs.kidger.site/equinox/api/module/module/#equinox.Module) is kind of like PyTorch's [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). However, PyTorch modules:\n",
    "    \n",
    "    - are not PyTrees, because PyTorch has no general, built-in concept of PyTrees;\n",
    "    - are not automatically dataclasses, and it can be kind of [problematic](https://discuss.pytorch.org/t/how-to-use-dataclass-with-pytorch/53444/9) to convert them;\n",
    "    - define the model computation in the `forward` method, rather than `__call__`. Technically though, PyTorch still has to define `__call__` in the background to have its module objects behave like functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation and `vmap`\n",
    "\n",
    "The power of pytrees goes much deeper than we've seen here. The core JAX transformations, jax.vmap and jax.grad\n",
    "\n",
    "!!! NOTE    \n",
    "    If you run into problems with `jax.vmap`, try using Equinox's `filter_vmap` as we've done above. It does the same thing, but a little more intelligently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and states\n",
    "\n",
    "JAX [plays best](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#pure-functions) with [pure functions](https://en.wikipedia.org/wiki/Purely_functional_programming). Let's see what that means.\n",
    "\n",
    "Perhaps you are familiar with object-oriented programming, where *classes* define how objects possess and manipulate their *internal states*. For example, let's define a type of object that 1) possesses two attributes, and 2) when it's called, returns a result, but also internally updates one of its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tx\tsmee\n",
      "Step 0:\t\t2\t0\n",
      "Step 1:\t\t4\t0\n",
      "Step 2:\t\t8\t2\n",
      "Step 3:\t\t16\t2\n",
      "Step 4:\t\t32\t2\n",
      "Step 5:\t\t64\t2\n",
      "Step 6:\t\t128\t2\n"
     ]
    }
   ],
   "source": [
    "class StatefulFoo:\n",
    "    smee: int\n",
    "    a: int\n",
    "\n",
    "    def __init__(self, a: int):\n",
    "        self.smee = 0\n",
    "        self.a = a\n",
    "\n",
    "    def __call__(self, x: int):\n",
    "\n",
    "        if x > 3:\n",
    "            self.smee = 2\n",
    "\n",
    "        return self.a * x\n",
    "\n",
    "\n",
    "a = 2\n",
    "foo = StatefulFoo(a)\n",
    "x = 1\n",
    "\n",
    "print(\"\\t\\tx\\tsmee\")\n",
    "\n",
    "for i in range(7):\n",
    "    x = foo(x)\n",
    "\n",
    "    print(f\"Step {i}:\\t\\t{x}\\t{foo.smee}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, the internal state—the value of `foo.smee`—changes once a certain value is passed to `foo`. This is obvious in this case, since we're printing `foo.smee` on every step. But under different circumstances, we might not even know it had changed.\n",
    "\n",
    "Seen as a function, the main thing that `foo` does is to return `result`. But it also has the *side effect* of altering `foo.smee`.\n",
    "\n",
    "On the other hand, *a pure function does not have side effects*. Everything that the function does, is how its input gets turned into its return value. \n",
    "\n",
    "We can still do what we did with `foo.smee`, except that `smee` can no longer be hidden. It just needs to be part of the input and output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tx\tsmee\n",
      "Step 0:\t\t2\t0\n",
      "Step 1:\t\t4\t0\n",
      "Step 2:\t\t8\t2\n",
      "Step 3:\t\t16\t2\n",
      "Step 4:\t\t32\t2\n",
      "Step 5:\t\t64\t2\n",
      "Step 6:\t\t128\t2\n"
     ]
    }
   ],
   "source": [
    "class PureFoo:\n",
    "    a: int\n",
    "\n",
    "    def __init__(self, a: int):\n",
    "        self.a = a\n",
    "\n",
    "    def __call__(self, x: int, smee: int):\n",
    "\n",
    "        if x > 3:\n",
    "            smee = 2\n",
    "\n",
    "        return self.a * x, smee\n",
    "\n",
    "a = 2\n",
    "foo = PureFoo(a)\n",
    "smee = 0\n",
    "x = 1\n",
    "\n",
    "print(\"\\t\\tx\\tsmee\")\n",
    "\n",
    "for i in range(7):\n",
    "    x, smee = foo(x, smee)\n",
    "\n",
    "    print(f\"Step {i}:\\t\\t{x}\\t{smee}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe this doesn't seem as nice as `StatefulFoo`, but it is totally transparent. And if we keep building up our programs in this way, it forces us to start adding more structure to the inputs and outputs of our functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PureFoo() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Data(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39mx, smee)\n\u001b[1;32m     20\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 21\u001b[0m foo \u001b[38;5;241m=\u001b[39m \u001b[43mPureFoo\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m data \u001b[38;5;241m=\u001b[39m Data(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, smee\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124msmee\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: PureFoo() takes no arguments"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Data:\n",
    "    x: int\n",
    "    smee: int\n",
    "\n",
    "\n",
    "class PureFoo:\n",
    "    a: int\n",
    "\n",
    "    def __init__(self, a: int):\n",
    "        self.a = a\n",
    "\n",
    "    def __call__(self, data: Data):\n",
    "\n",
    "        if data.x > 3:\n",
    "            smee = 2\n",
    "        else:\n",
    "            smee = data.smee\n",
    "\n",
    "        return Data(2 * data.x, smee)\n",
    "\n",
    "\n",
    "a = 2\n",
    "foo = PureFoo(a)\n",
    "data = Data(x=1, smee=0)\n",
    "\n",
    "print(\"\\t\\tx\\tsmee\")\n",
    "\n",
    "for i in range(7):\n",
    "    data = foo(data)\n",
    "\n",
    "    print(f\"Step {i}:\\t\\t{data.x}\\t{data.smee}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that as our programs grow complex, this style will work at least as well as the stateful style ever did—and without hiding anything.\n",
    "\n",
    "!!! Note \"\"\n",
    "    In Feedbax, the relationship between a model and its state is like the relationship between `PureFoo` and `Data`, in this example. A model does not *possess* state, it *operates* on it. \n",
    "    \n",
    "    Similarly, we never change a state object by directly reassigning its values. For example, in the above example we would never do this:\n",
    "    \n",
    "    ```python\n",
    "    data = Data(x=1, smee=0)\n",
    "    data.smee = 2\n",
    "    ```\n",
    "    \n",
    "    As we'll see shortly, this won't be a problem. We'll just need to define the alteration to `data` as some function that takes `data` as its input, and constructs the altered version as its output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equinox and pure functions\n",
    "\n",
    "It might seem a little odd that we contrasted object oriented programming with purely functional programming, and then we kept defining our \"pure function\" as a  `class`!\n",
    "\n",
    "It's not really odd, though. What matters is that our classes *behave* like pure function because of the way we define `__call__`. And classes do one very convenient thing for us: they let us keep fixed model parameters (like `a`) in the same place as the function that defines the model's computation.\n",
    "\n",
    "This is essentially what `eqx.Module` is for. What's more, it forces us to code in a functional style. Watch what happens if we try to change one of the attributes of an Equinox module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "FrozenInstanceError",
     "evalue": "cannot assign to field 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFrozenInstanceError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m     a: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m      4\u001b[0m b \u001b[38;5;241m=\u001b[39m Bar(a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "File \u001b[0;32m<string>:4\u001b[0m, in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n",
      "\u001b[0;31mFrozenInstanceError\u001b[0m: cannot assign to field 'a'"
     ]
    }
   ],
   "source": [
    "class Bar(eqx.Module):\n",
    "    a: int\n",
    "\n",
    "my_bar = Bar(a=3)\n",
    "\n",
    "my_bar.a = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things are no different if the object tries to mutate itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "FrozenInstanceError",
     "evalue": "cannot assign to field 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFrozenInstanceError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m      8\u001b[0m my_baz \u001b[38;5;241m=\u001b[39m Baz(a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmy_baz\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[93], line 5\u001b[0m, in \u001b[0;36mBaz.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma\u001b[49m \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m<string>:4\u001b[0m, in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n",
      "\u001b[0;31mFrozenInstanceError\u001b[0m: cannot assign to field 'a'"
     ]
    }
   ],
   "source": [
    "class Baz(eqx.Module):\n",
    "    a: int\n",
    "\n",
    "    def __call__(self, x: int):\n",
    "        self.a = x\n",
    "\n",
    "\n",
    "my_baz = Baz(a=3)\n",
    "\n",
    "my_baz(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, Equinox modules are *immutable*. Immutability goes hand in hand with pure functions, because it ensures that the internal state of our objects cannot be altered in the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random number generation\n",
    "\n",
    "One way that differs from NumPy API; PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing surgery\n",
    "\n",
    "We have a model. It's an immutable PyTree. We want to change just one part of it. How can we do that?\n",
    "\n",
    "Let's start with a [pre-built model](/feedbax/examples/0_train_simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA backend failed to initialize: Unable to load CUDA. Is it installed? (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/home/mll/.miniforge3/envs/fx/lib/python3.11/site-packages/diffrax/adjoint.py:665: UserWarning: As of Equinox 0.10.7, `equinox.filter_custom_vjp.defvjp` is deprecated in favour of `.def_fwd` and `.def_bwd`. This new API supports symbolic zeros, which allow for more efficient autodifferentiation rules. In particular:\n",
      "- the fwd and bwd functions take an extra `perturbed` argument, which     indicates which primals actually need a gradient. You can use this     to skip computing the gradient for any unperturbed value. (You can     also safely just ignore this if you wish.)\n",
      "- `None` was previously passed to indicate a symbolic zero gradient for     all objects that weren't inexact arrays, but all inexact arrays     always had an array-valued gradient. Now, `None` may also be passed     to indicate that an inexact array has a symbolic zero gradient.\n",
      "  _loop_backsolve.defvjp(_loop_backsolve_fwd, _loop_backsolve_bwd)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "from feedbax.xabdeef import point_mass_nn_simple_reaches\n",
    "\n",
    "\n",
    "context = point_mass_nn_simple_reaches(key=jax.random.PRNGKey(0))\n",
    "model = context.model  # Shorthand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has a point mass of mass $1.0$ as its skeleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointMass(mass=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.step.mechanics.plant.skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to directly alter the model to use a point mass of mass $5.0$, an error is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FrozenInstanceError",
     "evalue": "cannot assign to field 'skeleton'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFrozenInstanceError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeedbax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmechanics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mskeleton\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PointMass \n",
      "\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Try to replace the entire point mass\u001b[39;00m\n",
      "\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmechanics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskeleton\u001b[49m \u001b[38;5;241m=\u001b[39m PointMass(\u001b[38;5;241m5.0\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m<string>:4\u001b[0m, in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n",
      "\n",
      "\u001b[0;31mFrozenInstanceError\u001b[0m: cannot assign to field 'skeleton'"
     ]
    }
   ],
   "source": [
    "from feedbax.mechanics.skeleton import PointMass\n",
    "\n",
    "# Try to replace the entire point mass\n",
    "model.step.mechanics.plant.skeleton = PointMass(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FrozenInstanceError",
     "evalue": "cannot assign to field 'mass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFrozenInstanceError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Try to just change the mass\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmechanics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskeleton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmass\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.0\u001b[39m\n",
      "\n",
      "File \u001b[0;32m<string>:4\u001b[0m, in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n",
      "\n",
      "\u001b[0;31mFrozenInstanceError\u001b[0m: cannot assign to field 'mass'"
     ]
    }
   ],
   "source": [
    "# Or just try to change the mass\n",
    "model.step.mechanics.plant.skeleton.mass = 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of direct re-assignment is common in Python. It might seem inconvenient to have it outlawed! \n",
    "\n",
    "Well, it is still possible to alter our model. But if we want to switch out just the point mass, we have to do something slightly more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "\n",
    "model_heavy = eqx.tree_at(\n",
    "    lambda m: m.step.mechanics.plant.skeleton,\n",
    "    model,\n",
    "    PointMass(5.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To replace a part of our model tree, we use the `tree_at` function provided by Equinox. \n",
    "\n",
    "The use of `lambda` in the first agument to `tree_at` is similar to the `lambda` we used in Example 1. There, we defined a function `where_train` that picked out which parts of the model should be trainable. Here, our function picks out which part of our model will be replaced.\n",
    "\n",
    "The second argument is just `model`, which is the model we want to alter. \n",
    "\n",
    "The third argument is the part we want to replace it with.\n",
    "\n",
    "Why the added complexity? *It forces us never to alter our models in-place*. The function `eqx.tree_at` does not modify `model` directly, but *returns a copy* of `model` which possesses the alterations. Here, we assign the new object to `model_heavy`, since maybe we want to be able to refer to both the original model (still called `model`!) and the altered one. But we could just as easily have written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eqx.tree_at(\n",
    "    lambda m: m.step.mechanics.plant.skeleton,\n",
    "    model,\n",
    "    PointMass(5.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means \"create an altered model, and make it so that `model` now refers to the new model---I don't need to refer to the original one by that name anymore\".\n",
    "\n",
    "There are downstream advantages to our ban. The downside to in-place changes is that it can be hard to keep track of their hidden consequences. Some parts of my code may depend on a given object, and if other parts of my code can reach into that object and make implicit alterations, the relationships within my code may be altered without consent of all the stakeholders, so to speak.\n",
    "\n",
    "When we are forced to *return* an altered object rather than *mutate* an existing object, the consequences are always out in the open. We have to be explicit about what-refers-to-what, with respect to what-has-changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We also can't alter JAX arrays in-place. Use of `at` and `set`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
