{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with stages\n",
    "\n",
    "In this example, we'll check out\n",
    "\n",
    "- the structure of Feedbax staged models;\n",
    "- how thir structure allows them to be modified with arbitrary interventions;\n",
    "- how to write your own staged models.\n",
    "\n",
    "All Feedbax models, staged or not, are defined as [Equinox]((/feedbax/examples/pytrees#equinox)) `Module` objects. These may be composed of other `Module` objects, forming a [nested structure](/feedbax/examples/1_train#examining-the-models-tree-structure) of model components and their parameters. \n",
    "\n",
    "Once a model object is constructed, we can call it like a function. We're allowed to do that because we [define its `__call__` method](https://docs.python.org/3/reference/datamodel.html#class-instances). \n",
    "\n",
    "## The structure of a staged model\n",
    "\n",
    "A lot can happen in `__call__`. \n",
    "\n",
    "Consider the following simplified definition of [`feedbax.bodies.SimpleFeedback`][feedbax.bodies.SimpleFeedback], which is a model of a single time step in which a neural network, after receiving some sensory feedback, sends a command to a mechanical model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import equinox as eqx\n",
    "\n",
    "\n",
    "class SimpleFeedbackState(eqx.Module):\n",
    "    mechanics: MechanicsState\n",
    "    net: NetworkState\n",
    "    feedback: ChannelState\n",
    "\n",
    "\n",
    "class SimpleFeedback(eqx.Module):\n",
    "    \"\"\"Model of one step around a feedback loop between a neural network \n",
    "    and a mechanical model.\n",
    "    \"\"\"\n",
    "    mechanics: Mechanics \n",
    "    net: eqx.Module  \n",
    "    feedback_channel: Channel\n",
    "    where_feedback: Callable[[SimpleFeedbackState], PyTree] = (\n",
    "        lambda state: state.mechanics.plant.skeleton\n",
    "    )\n",
    "    \n",
    "    def __call__(\n",
    "        self, \n",
    "        input: PyTree[Array],  \n",
    "        state: SimpleFeedbackState, \n",
    "        key: PRNGKeyArray,\n",
    "    ) -> SimpleFeedbackState:\n",
    "                \n",
    "        key1, key2 = jr.split(key)\n",
    "        \n",
    "        feedback_state = self.feedback_channel(\n",
    "            self.where_feedback(state),\n",
    "            state.feedback,\n",
    "            key1,\n",
    "        )\n",
    "        \n",
    "        network_state = self.net(\n",
    "            (input, feedback_state.output), \n",
    "            state.network, \n",
    "            key2\n",
    "        )\n",
    "        \n",
    "        mechanics_state = self.mechanics(\n",
    "            network_state.output, \n",
    "            state.mechanics\n",
    "        )        \n",
    "        \n",
    "        return SimpleFeedbackState(\n",
    "            mechanics=mechanics_state, \n",
    "            network=network_state,\n",
    "            feedback=feedback_state,\n",
    "        )\n",
    "    \n",
    "    # ...\n",
    "    # We've omitted a bunch of other stuff from this definition!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, notice that `SimpleFeedback` is an Equinox `Module` subclass. It's not obvious from this code alone, but [`Mechanics`][feedbax.mechanics.Mechanics] and [`Channel`][feedbax.channel.Channel] are also `Module` subclasses, with their own parameters and submodules. \n",
    "\n",
    "Observe the following about `__call__`. It:\n",
    "\n",
    "- takes a `SimpleFeedbackState` object, and returns a new one. This is where \"the state of the model\" is actually stored, not in `SimpleFeedback` itself.\n",
    "- also takes an argument `input`. This argument is a PyTree that includes any inputs to the model that aren't part of its state.\n",
    "- contains several steps. Each step involves calling one of the components of the model, such as `self.feedback_channel` and `self.net`. Each component is passed some part of the model state, and returns an updated version of that part. Like the parent model, each component also takes an argument of additional information as input. \n",
    "\n",
    "    !!! quote \"\"    \n",
    "        \n",
    "        The components of the model that are called during `__call__` are\n",
    "    \n",
    "        === \"`self.feedback_channel`\"\n",
    "            \n",
    "            - takes as input `self.where_feedback(state)`, which is the part of `state` we want to store in the state of the feedback channel, to be retrieved on some later time step, depending on the delay.\n",
    "            - takes `state.feedback` as its prior state. This is a `ChannelState` object.\n",
    "            - returns an updated `Channel_State`, which we assign to `feedback_state`.\n",
    "            \n",
    "            Note that the default for `self.where_feedback` is `lambda state: state.mechanics.plant.skeleton`, which means that our sensory feedback consists of the full state of the skeleton—typically, the positions and velocities of some joints.\n",
    "            \n",
    "        === \"`self.net`\"\n",
    "        \n",
    "            - takes as input `(input, feedback_state.output)`. Here, `input` is the entire argument passed to `__call__` itself. Since `SimpleFeedback` is a top-level model, its `input` will consist of the trial-by-trial information needed to complete the task. The neural network is proper recipient of this information, in this case.\n",
    "            - takes `state.network` as prior state. This is a `NetworkState` object.\n",
    "            - returns an updated `NetworkState`, which we assign to `network_state`.\n",
    "            \n",
    "            This is the only step in the model that receives the `input` that was passed to `SimpleFeedback` itself. This is because the input to the model is typically information the network needs to complete the task—say, the position of the goal it should reach to. The input to all of the other model steps is some other part of the model state.\n",
    "        \n",
    "        === \"`self.mechanics`\"\n",
    "\n",
    "            - takes as input `network_state.output`, where `network_state` contains the updated `NetworkState` returned by `self.net`: `network_state.output` is the command we want to send to the mechanical model.\n",
    "            - takes `state.mechanics` as its prior state. This is a `MechanicsState` object.\n",
    "            - returns an updated `MechanicsState`, which we assign to `mechanics_state`.\n",
    "        \n",
    "- builds and returns a new `SimpleFeedbackState`, after calling all the model steps and getting their updates to various parts of the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to intervene\n",
    "\n",
    "What if we want to interfere with the command the neural network generates, after we call `self.net` but before we call `self.mechanics`? We could write a new module with an extra component that operates on `NetworkState`, and call it at the right moment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py hl_lines=\"1 8 31 32\"\n",
    "class SimpleFeedbackPerturbNetworkOutput(eqx.Module):\n",
    "    net: eqx.Module  \n",
    "    mechanics: Mechanics \n",
    "    feedback_channel: Channel\n",
    "    where_feedback: Callable[[SimpleFeedbackState], PyTree] = (\n",
    "        lambda state: state.mechanics.plant.skeleton\n",
    "    )\n",
    "    intervention: eqx.Module\n",
    "    \n",
    "    def __call__(\n",
    "        self, \n",
    "        input: PyTree[Array],  \n",
    "        state: SimpleFeedbackState, \n",
    "        key: PRNGKeyArray,\n",
    "    ) -> SimpleFeedbackState:\n",
    "                \n",
    "        key1, key2 = jr.split(key)\n",
    "        \n",
    "        feedback_state = self.feedback_channel(\n",
    "            self.where_feedback(state),\n",
    "            state.feedback,\n",
    "            key1,\n",
    "        )\n",
    "        \n",
    "        network_state = self.net(\n",
    "            (input, feedback_state.output), \n",
    "            state.network, \n",
    "            key2\n",
    "        )\n",
    "        \n",
    "        # modifies `network_state.output` somehow\n",
    "        network_state = self.intervention(network_state)\n",
    "        \n",
    "        mechanics_state = self.mechanics(\n",
    "            network_state.output, \n",
    "            state.mechanics\n",
    "        )        \n",
    "        \n",
    "        return SimpleFeedbackState(\n",
    "            mechanics=mechanics_state, \n",
    "            network=network_state,\n",
    "            feedback=feedback_state,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be pretty inconvenient to have to do this every time we want to intervene a little. Once we have a model, it'd be nice to experiment on it quickly. \n",
    "\n",
    "Also, if we have a different model that's similar enough to `SimpleFeedback` that it might make sense to use the same kind of `NetworkState` intervention on it that we just used, we wouldn't want to have to manually rewrite that model too. \n",
    "\n",
    "Thankfully we can do something about this. \n",
    "\n",
    "### A more general way to intervene\n",
    "\n",
    "Start by noticing that each step in the `__call__` method of our original `SimpleFeedback`:\n",
    "\n",
    "- is defined as a modification of some part of the model state: each operation we perform returns some part of `SimpleFeedbackState`;\n",
    "- calls a model component in a consistent way: no matter if we're calling `self.feedback_channel`, `self.net`, or `self.mechanics`, our call always looks like `self.something(input_to_something, state_associated_with_something, key)`.\n",
    "\n",
    "!!! Note inline end \"\"\n",
    "    Each component will also need a `key`, but we won't need to specify how that works for each component individually. \n",
    "    \n",
    "    We'll just have to be sure to split up the `key` passed to `__call__`, so that each component gets a different key.\n",
    "\n",
    "That means we can define each step in `__call__` with three pieces of information: \n",
    "\n",
    "1. Which model component to call—say, `self.net`;\n",
    "2. How to select the input to that model component, from the full `input` and `state` passed to `SimpleFeedback`;\n",
    "3. How to select the state associated with (and modified by) that model component, out of the full `state` passed to `SimpleFeedback`.\n",
    "\n",
    "OK, let's try to do that. We'll define an object called `ModelStage` which holds the three pieces of information required to define each model stage. Then we'll define a `model_spec` that defines all the stages of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class ModelStage(eqx.Module):\n",
    "    component: Callable\n",
    "    where_input: Callable\n",
    "    where_state: Callable\n",
    "\n",
    "\n",
    "model_spec = dict({\n",
    "    'update_feedback': ModelStage(\n",
    "        # See explanation below for why we define this as a lambda!\n",
    "        func=lambda self: self.feedback_channel,  \n",
    "        where_input=lambda input, state: self.where_feedback(state),\n",
    "        where_state=lambda state: state.feedback,  \n",
    "    ),\n",
    "    'net_step': ModelStage(\n",
    "        func=lambda self: self.net,\n",
    "        where_input=lambda input, state: (input, state.feedback.output),\n",
    "        where_state=lambda state: state.net,                \n",
    "    ),\n",
    "    'mechanics_step': ModelStage(\n",
    "        func=lambda self: self.mechanics,\n",
    "        where_input=lambda input, state: state.net.output,\n",
    "        where_state=lambda state: state.mechanics,\n",
    "    ),\n",
    "})       \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! NOTE   \n",
    "    Each of the fields in `ModelStage` is typed as `Callable`, which means it can be a function, a method, or any object with `__call__` defined. In this case, we define them inline as `lambda` functions.\n",
    "    \n",
    "    For `where_input` and `where_state`, this is similar to what we've seen in [earlier examples](/feedbax/examples/1_train#selecting-part-of-the-model-to-train). For example, `where_input` will take the `input` and `state` passed to `__call__`, and return the parts to be passed to the current stage's `func`.\n",
    "    \n",
    "    Why do we define `func` as `#!py lambda self: self.something` rather than just `#!py self.something`? It's to make sure that references to the component \"stay fresh\". If that doesn't make sense to you, don't worry about it at this point. Just remember that if you write your own staged models, you will need to write your `model_spec` this way.\n",
    "\n",
    "In order to insert interventions at arbitrary points, here's what we'll do: \n",
    "\n",
    "1. include `model_spec` as an attribute of `SimpleFeedback` itself;\n",
    "2. define `__call__` so that it calls each of the components in `model_spec`, passing them their respective subsets of the input and state, and using their return value to update the model state.    \n",
    "\n",
    "    !!! Warning \"\"    \n",
    "    \n",
    "        Importantly, the way we define `__call__` will no longer allow our model stages to assign, or refer, to intermediate variables like `feedback_state`. This is why in the `model_spec` we just defined, the input to `self.net` includes `state.feedback.output`, where in our original definition of `SimpleFeedback` we had passed `feedback_state.output`.\n",
    "        \n",
    "        In our new `__call__`, we'll update the full model state *immediately* after each stage, rather than assigning to intermediate variables and then finally constructing a new `SimpleFeedbackState`. Every stage's inputs are only selected out of the full model state, not out of intermediate copies of parts of the state.\n",
    "        \n",
    "3. give `SimpleFeedback` a new attribute `intervenors`, where we can insert additional components that intervene on the model's state, *given the name of the model stage they should be applied before*. For example, if this attribute is set to `{'mechanics_step': [some_intervention, some_other_intervention]}` then `some_intervention` and `some_other_intervention` would be called one after the other, *immediately before* `self.mechanics` is called.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='simple_feedback_general_def'></a>\n",
    "```python\n",
    "class SimpleFeedback(eqx.Module):\n",
    "    net: eqx.Module  \n",
    "    mechanics: Mechanics \n",
    "    feedback_channel: Channel\n",
    "    where_feedback: Callable[[SimpleFeedbackState], PyTree] = \\\n",
    "        lambda state: state.mechanics.plant.skeleton\n",
    "    intervenors: dict[str, eqx.Module]    \n",
    "    \n",
    "    @property\n",
    "    def model_spec(self):\n",
    "        return dict({\n",
    "            'update_feedback': ModelStage(\n",
    "                func=lambda self: self.feedback_channel,  \n",
    "                where_input=lambda input, state: self.where_feedback(state),\n",
    "                where_state=lambda state: state.feedback,  \n",
    "            ),\n",
    "            'net_step': ModelStage(\n",
    "                func=lambda self: self.net,\n",
    "                where_input=lambda input, state: (input, state.feedback.output),\n",
    "                where_state=lambda state: state.net,                \n",
    "            ),\n",
    "            'mechanics_step': ModelStage(\n",
    "                func=lambda self: self.mechanics,\n",
    "                where_input=lambda input, state: state.net.output,\n",
    "                where_state=lambda state: state.mechanics,\n",
    "            ),\n",
    "        })    \n",
    "    \n",
    "    def __call__(\n",
    "        self, \n",
    "        input: PyTree[Array],  \n",
    "        state: SimpleFeedbackState, \n",
    "        key: PRNGKeyArray,\n",
    "    ) -> SimpleFeedbackState: \n",
    "    \n",
    "        # Get a different key for each stage of the model.\n",
    "        keys = jr.split(key, len(self.model_spec))\n",
    "        \n",
    "        # Loop through the model stages, pairing them with their keys.\n",
    "        for (label, stage), key_stage in zip(self.model_spec.items(), keys):\n",
    "            \n",
    "            # Loop through all intervenors assigned to this model stage.\n",
    "            for intervenor in self.intervenors[label]:\n",
    "                state = intervenor(state)\n",
    "            \n",
    "            # Get the updated part of the state associated with the stage\n",
    "            new_component_state = stage.func(\n",
    "                stage.where_input(input, state),\n",
    "                stage.where_state(state),\n",
    "                key_stage,\n",
    "            )\n",
    "            \n",
    "            # Modify the full model state\n",
    "            state = eqx.tree_at(\n",
    "                stage.where_state,  # Part to modify\n",
    "                state,  # What is modified (full state)\n",
    "                new_component_state,  # New part to insert\n",
    "            )\n",
    "        \n",
    "        return state\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is now structured so that it's possible to [insert interventions](/feedbax/examples/3_intervening/#adding-a-force-field) among its stages, without rewriting the whole thing each time!\n",
    "\n",
    "This `__call__` method is too general to be limited to `SimpleFeedback`. In fact, the real [`feedbax.bodies.SimpleFeedback`][feedbax.bodies.SimpleFeedback] doesn't define `__call__` itself, but inherits it from [`feedbax.AbstractStagedModel`][feedbax.AbstractStagedModel]. \n",
    "\n",
    "Every staged model is a subclass of `AbstractStagedModel`, and only needs to define `model_spec` (and a couple of other smaller things)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining models as a sequence of named state operations has some additional advantages, beyond being able to insert interventions among the stages. For one, it makes it easy to [log the details](/feedbax/examples/debugging/#logging-details-of-model-execution) of our model stages as they are executed, which is useful for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty printing of model stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another advantage of staged models is that it's easy to print out a tree of operations, showing the sequence in which the're performed.\n",
    "\n",
    "Feedbax provides the function [`pprint_model_spec`][feedbax.pprint_model_spec] for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update_feedback: MultiModel\n",
      "nn_step: SimpleStagedNetwork\n",
      "  hidden: GRUCell\n",
      "  readout: SimpleStagedNetwork._output\n",
      "mechanics_step: Mechanics\n",
      "  convert_effector_force: PointMass.update_state_given_effector_force\n",
      "  statics_step: DirectForceInput\n",
      "    clip_skeleton_state: DirectForceInput._clip_state\n",
      "  dynamics_step: Mechanics._dynamics_step\n",
      "  get_effector: PointMass.effector\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "from feedbax import pprint_model_spec\n",
    "from feedbax.xabdeef import point_mass_nn_simple_reaches\n",
    "\n",
    "context = point_mass_nn_simple_reaches(key=jax.random.PRNGKey(0))\n",
    "\n",
    "pprint_model_spec(context.model.step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line corresponds to a model stage. When the component for that stage is also a staged model, its own stages are printed on the lines that follow, with indentation. For example, `\"clip_skeleton_state\"` is a stage of `DirectForceInput`, which is called as part of the `\"statics_step\"` stage of `Mechanics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a staged model\n",
    "\n",
    "The following components are needed to define your own staged model.\n",
    "\n",
    "1. A [final](https://docs.kidger.site/equinox/pattern/) subclass of [`AbstractState`][feedbax.AbstractState] that defines the states that the model will be able to operate on. The fields of this subclass are typically JAX arrays, or other subclasses of `AbstractState` that are associated with the model's components. For example, if the model has a `Mechanics` component, its state should have a `MechanicsState` field.\n",
    "2. A final subclass of [`AbstractStagedModel`][feedbax.AbstractStagedModel]. This subclass must implement \n",
    "    - a `model_spec` property defining, as above, the information needed to call the model stages;\n",
    "    - an `init` method that takes a random key, and returns a default model state of the type defined in 1;\n",
    "    - the field `intervenors: Mapping[str, Sequence[AbstractIntervenor]]`, where intervenors will be stored. \n",
    "    \n",
    "For example, here's how to define a staged model that contains two neural networks in a loop, where the second network receives the first network's output after some delay, and at the beginning of the next iteration (time step) the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from collections.abc import Mapping, Sequence\n",
    "\n",
    "import jax\n",
    "from jaxtyping import PRNGKeyArray\n",
    "\n",
    "from feedbax import AbstractStagedModel, ModelStage\n",
    "from feedbax.channel import Channel, ChannelState\n",
    "from feedbax.intervene import AbstractIntervenor\n",
    "from feedbax.nn import SimpleStagedNetwork, NetworkState\n",
    "from feedbax.state import AbstractState\n",
    "\n",
    "\n",
    "class NetworkLoopState(AbstractState):\n",
    "    net1: NetworkState\n",
    "    net2: NetworkState\n",
    "    channel: ChannelState\n",
    "\n",
    "\n",
    "class NetworkLoop(AbstractStagedModel[NetworkLoopState]):\n",
    "    net1: SimpleStagedNetwork\n",
    "    net2: SimpleStagedNetwork\n",
    "    channel: Channel\n",
    "    intervenors: dict[str, Sequence[AbstractIntervenor]]\n",
    "\n",
    "    @property\n",
    "    def model_spec(self) -> OrderedDict[str, ModelStage]:\n",
    "        return OrderedDict({\n",
    "            'net1_step': ModelStage(\n",
    "                callable=lambda self: self.net1,\n",
    "                where_input=lambda input, state: state.net2.output,\n",
    "                where_output=lambda state: state.net1,\n",
    "            ),\n",
    "            'channel': ModelStage(\n",
    "                callable=lambda self: self.channel,\n",
    "                where_input=lambda input, state: state.net1.output,\n",
    "                where_output=lambda state: state.channel,\n",
    "            ),\n",
    "            'net2_step': ModelStage(\n",
    "                callable=lambda self: self.net2,\n",
    "                where_input=lambda input, state: state.channel.output,\n",
    "                where_output=lambda state: state.net2,\n",
    "            ),\n",
    "        })\n",
    "\n",
    "    def init(self, *, key: PRNGKeyArray | None = None) -> NetworkLoopState:\n",
    "        keys = jax.random.split(key, 3)\n",
    "        return NetworkLoopState(\n",
    "            net1=self.net1.init(key=keys[0]),\n",
    "            net2=self.net2.init(key=keys[1]),\n",
    "            channel=self.channel.init(key=keys[2]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct this model, we have to construct its components. Normally we write a [setup function](/feedbax/examples/saving_and_loading) to make this reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "\n",
    "def setup(\n",
    "    net1_hidden_size,\n",
    "    net2_hidden_size,\n",
    "    channel_delay=5,\n",
    "    channel_noise_std=0.05,\n",
    "    *,\n",
    "    key,\n",
    "):\n",
    "    key1, key2 = jr.split(key)\n",
    "    net1 = SimpleStagedNetwork(\n",
    "        input_size=net2_hidden_size,\n",
    "        hidden_size=net1_hidden_size,\n",
    "        key=key1,\n",
    "    )\n",
    "    net2 = SimpleStagedNetwork(\n",
    "        input_size=net1_hidden_size,\n",
    "        hidden_size=net2_hidden_size,\n",
    "        key=key2\n",
    "    )\n",
    "    channel = Channel(\n",
    "        channel_delay,\n",
    "        channel_noise_std,\n",
    "        input_proto=jnp.zeros(net2_hidden_size)\n",
    "    )\n",
    "\n",
    "    return NetworkLoop(net1=net1, net2=net2, channel=channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we haven't defined what we would be using such a model for. For one, notice that none of the stages of `NetworkLoop` pass any part of the `input` to their respective components—so the networks couldn't be directly receiving any task information. (However, we can still imagine optimizing for certain targets inside the network during training. And we could imagine that this is just a motif we would use as part of a larger model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using stateless modules and simple functions as components\n",
    "\n",
    "Some components may be able to take one part of the model's state as input, and return another part as output, without having their own associated state. Often these are components whose inputs and outputs are single JAX arrays.\n",
    "\n",
    "For example, consider the `\"readout\"` stage of `SimpleStagedNetwork`, which operates on `NetworkState`. The component for this stage is an `eqx.nn.Linear` layer. Notice that [`Linear.__call__`](https://docs.kidger.site/equinox/api/nn/linear/#equinox.nn.Linear.__call__) only takes a single argument, `x: Array`. This is the input array to the linear layer, which in our case corresponds to `state.hidden`—the activity of the hidden layer of our network. The output of the layer is used to update `state.output`.\n",
    "\n",
    "Looking back at our generalized definition of `__call__` for staged models, each model stage is called like\n",
    "\n",
    "!!! Note inline end \"\"\n",
    "    As is generally the case for Feedbax and Equinox modules, `Linear` also has an argument `key`—but being a non-stochastic layer, will simply ignore it if passed.\n",
    "    \n",
    "    If the component doesn't take a `key` argument at all, the solution is similar to what we discuss below.\n",
    "    \n",
    "```python \n",
    "    # Get the updated part of the state associated with the stage\n",
    "    new_component_state = stage.func(\n",
    "        stage.where_input(input, state),\n",
    "        stage.where_state(state),\n",
    "        key_stage,\n",
    "    )\n",
    "```\n",
    "\n",
    "Not including the key, *two* arguments are passed, after being selected by `where_input` and `where_state`. Clearly this will raise an error if `stage.func` refers to a single-argument module like `Linear`.\n",
    "\n",
    "When we define our `model_spec`, we have to be careful in these cases. Here's a sketch of how we could define this stage:\n",
    "\n",
    "```python\n",
    "class StagedNetWithReadout(AbstractStagedModel[NetworkState]):\n",
    "    readout: eqx.nn.Linear\n",
    "    ...\n",
    "\n",
    "    @property \n",
    "    def model_spec(self):\n",
    "        return OrderedDict({\n",
    "            ...,\n",
    "            'readout': ModelStage(\n",
    "                func=lambda self: (\n",
    "                    lambda input, state, *, key: self.readout(input)\n",
    "                ),\n",
    "                where_input=lambda input, state: state.hidden,\n",
    "                where_state=lambda state: state.output,\n",
    "            )\n",
    "            ...,\n",
    "        })\n",
    "```\n",
    "\n",
    "We wrap `self.readout` inside a second lambda, which passes the `where_input(...)` argument on to `Linear`, but simply discards the `where_state(...)` argument. Note that `where_state` still needs to be defined, since it's also used to determine which part of the model's state to update with the *output* of the linear layer.\n",
    "\n",
    "!!! Info \"\"\n",
    "    If you find the double-lambda hard to read, you might prefer the function ['feedbax.wrap_stateless_callable'][feedbax.wrap_stateless_callable]:\n",
    "    \n",
    "    ```python \n",
    "    func=lambda self: wrap_stateless_callable(self.readout),\n",
    "    ```    \n",
    "    \n",
    "    This function can also be used to discard a `key` that would be passed to the component:\n",
    "    \n",
    "    ```python \n",
    "    func=lambda self: wrap_stateless_callable(self.stateless_keyless_component, pass_key=False),\n",
    "    ``` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using non-staged components \n",
    "\n",
    "Say you have a complex neural network model which you'd like to use in Feedbax, but you don't want to rewrite the whole thing as a subclass of `AbstractStagedModel` with a `model_spec` that specifies operations on some type of `AbstractState`.\n",
    "\n",
    "That's fine: you can still use such a network as a component. The downside is you won't be able to insert interventions inside the network as easily. \n",
    "\n",
    "(For example. Do we need a wrapper to make it work with `NetworkState`? Or should we make `SimpleFeedbackState` have a `NetworkState | Array` field?) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
