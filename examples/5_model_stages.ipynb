{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with stages\n",
    "\n",
    "In this example, we'll consider the basic structure of Feedbax models, how that makes it possible to modify them with arbitrary interventions, and how to write models of your own that you can apply interventions to. \n",
    "\n",
    "Feedbax models are defined as Equinox `Module` objects, which may be composed of other `Module` objects, forming a nested structure of model components and their parameters. [Ref](/feedbax/examples/pytrees/#equinox)\n",
    "\n",
    "After constructing a model, we use it by calling it like a function. This is possible because we define its `__call__` method. Giving an object a method with this specific name is the standard way of making the object behave like a function, in Python.\n",
    "\n",
    "A lot can happen inside of `__call__`. Consider the following abridged definition of [`feedbax.bodies.SimpleFeedback`][feedbax.bodies.SimpleFeedback], which is a model of a single time step of a neural network sending a command to a mechanical model, based on sensory feedback it receives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class SimpleFeedbackState(eqx.Module):\n",
    "    mechanics: MechanicsState\n",
    "    network: NetworkState\n",
    "    feedback: ChannelState\n",
    "\n",
    "\n",
    "class SimpleFeedback(eqx.Module):\n",
    "    \"\"\"Model of one step around a feedback loop between a neural network \n",
    "    and a mechanical model.\n",
    "    \"\"\"\n",
    "    net: eqx.Module  \n",
    "    mechanics: Mechanics \n",
    "    feedback_channel: Channel\n",
    "    where_feedback: Callable[[SimpleFeedbackState], PyTree] = \\\n",
    "        lambda state: state.mechanics.plant.skeleton\n",
    "    \n",
    "    def __call__(\n",
    "        self, \n",
    "        input: PyTree[Array],  \n",
    "        state: SimpleFeedbackState, \n",
    "        key: PRNGKeyArray,\n",
    "    ) -> SimpleFeedbackState:\n",
    "                \n",
    "        key1, key2 = jr.split(key)\n",
    "        \n",
    "        feedback_state = self.feedback_channel(\n",
    "            self.where_feedback(state),\n",
    "            state.feedback,\n",
    "            key1,\n",
    "        )\n",
    "        \n",
    "        network_state = self.net(\n",
    "            (input, feedback_state.output), \n",
    "            state.network, \n",
    "            key2\n",
    "        )\n",
    "        \n",
    "        mechanics_state = self.mechanics(\n",
    "            network_state.output, \n",
    "            state.mechanics\n",
    "        )        \n",
    "        \n",
    "        return SimpleFeedbackState(\n",
    "            mechanics=mechanics_state, \n",
    "            network=network_state,\n",
    "            feedback=feedback_state,\n",
    "        )\n",
    "    \n",
    "    # ...\n",
    "    # We've omitted a bunch of other stuff from this definition!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several things to notice here:\n",
    "\n",
    "1. `SimpleFeedback` is an Equinox `Module` subclass, and it's composed of other `Module` objects. `Mechanics` and `Channel` are also `Module`s defined in a similar way, with their own parameters and submodules. This is why we can refer to `model.mechanics.plant.input_size`, for example, when `model` is a `SimpleFeedback` object.\n",
    "2. `__call__` takes a model state—a `SimpleFeedbackState`—and returns a new one. Like all Feedbax models, it also takes `input`, which is any input to the model in addition to its prior state. In general, the input to a model may be an arbitrary tree structure of data stored in JAX arrays (`PyTree[Array]`).\n",
    "3. `__call__` contains several steps. Each step involves calling one of the components of the model, which takes its own part of the model state, and returns a new version of that state. Each component also takes some other information as input, in addition to its prior state.     \n",
    "\n",
    "    === \"`self.feedback_channel`\"\n",
    "        \n",
    "        - takes `state.feedback` (a `ChannelState` object) as its prior state;\n",
    "        - also takes as input `self.where_feedback(state)`, which is the part of `state` we want to store in the state of the feedback channel, to be retrieved on some later time step, depending on the delay;\n",
    "        - returns an updated `Channel_State`, which we assign to `feedback_state`.\n",
    "        \n",
    "        Note that the default for `self.where_feedback` is `lambda state: state.mechanics.plant.skeleton`, which means that our sensory feedback consists of the full state of the skeleton—typically, the positions and velocities of some joints.\n",
    "        \n",
    "    === \"`self.net`\"\n",
    "    \n",
    "        - takes `state.network` (a `NetworkState` object) as prior state;\n",
    "        - also takes as input `(input, feedback_state.output)`—note that `input` is the entire argument passed to `__call__` itself;\n",
    "        - returns an updated `NetworkState`, which we assign to `network_state`.\n",
    "        \n",
    "        This is the only step in the model that receives the `input` that was passed to `SimpleFeedback` itself. This is because the input to the model is typically information the network needs to complete the task—say, the position of the goal it should reach to. The input to all of the other model steps is some other part of the model state.\n",
    "    \n",
    "    === \"`self.mechanics`\"\n",
    "\n",
    "        - takes `state.mechanics` (a `MechanicsState` object) as its prior state;\n",
    "        - also takes as input `network_state.output`, where `network_state` contains the updated `NetworkState` returned by `self.net`: `network_state.output` is the command we want to send to the mechanical model;\n",
    "        - returns an updated `MechanicsState`, which we assign to `mechanics_state`.\n",
    "        \n",
    "4. After calling all the model steps and getting update substates, we use them to build a new `SimpleFeedbackState` to return. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to interfere with the command the neural network generates, after we call `self.net` but before we call `self.mechanics`? We could write a new module with an extra component that operates on `NetworkState`, and call it at the right moment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py hl_lines=\"1 7 30 31\"\n",
    "class SimpleFeedbackPerturbNetworkOutput(eqx.Module):\n",
    "    net: eqx.Module  \n",
    "    mechanics: Mechanics \n",
    "    feedback_channel: Channel\n",
    "    where_feedback: Callable[[SimpleFeedbackState], PyTree] = \\\n",
    "        lambda state: state.mechanics.plant.skeleton\n",
    "    intervention: eqx.Module\n",
    "    \n",
    "    def __call__(\n",
    "        self, \n",
    "        input: PyTree[Array],  \n",
    "        state: SimpleFeedbackState, \n",
    "        key: PRNGKeyArray,\n",
    "    ) -> SimpleFeedbackState:\n",
    "                \n",
    "        key1, key2 = jr.split(key)\n",
    "        \n",
    "        feedback_state = self.feedback_channel(\n",
    "            self.where_feedback(state),\n",
    "            state.feedback,\n",
    "            key1,\n",
    "        )\n",
    "        \n",
    "        network_state = self.net(\n",
    "            (input, feedback_state.output), \n",
    "            state.network, \n",
    "            key2\n",
    "        )\n",
    "        \n",
    "        # modifies `network_state.output` somehow\n",
    "        network_state = self.intervention(network_state)\n",
    "        \n",
    "        mechanics_state = self.mechanics(\n",
    "            network_state.output, \n",
    "            state.mechanics\n",
    "        )        \n",
    "        \n",
    "        return SimpleFeedbackState(\n",
    "            mechanics=mechanics_state, \n",
    "            network=network_state,\n",
    "            feedback=feedback_state,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be pretty inconvenient to have to do this every time we want to intervene a little. Once we have a model, it'd be nice to experiment on it quickly. And if we have a different model that is similar enough to `SimpleFeedback` that it could make sense to use the same kind of `NetworkState` intervention on it that we just used, we wouldn't want to have to manually rewrite that model, too. \n",
    "\n",
    "Thankfully we can do something about this. Start by noticing that each step in the `__call__` method of our original `SimpleFeedback`:\n",
    "\n",
    "- is defined as a modification of some part of the model state—each operation we perform returns some part of `SimpleFeedbackState`;\n",
    "- calls a model component in a consistent way: no matter if we're calling `self.feedback_channel`, `self.net`, or `self.mechanics`, our call always looks like `self.something(input_to_something, state_associated_with_something, key)`.\n",
    "\n",
    "That means we can define each step in `__call__` with three pieces of information: \n",
    "\n",
    "1. What model component to call; e.g. `self.net`;\n",
    "2. How to select the input to that model component, out of all the `input` and `state` given to `SimpleFeedback`;\n",
    "3. How to select the state associated with (and modified by) that model component, out of the full `state` of `SimpleFeedback`.\n",
    "\n",
    "!!! NOTE\n",
    "    The `key` passed to each model component is no big deal. We just have to be sure to split up the `key` passed to `__call__`, so that each model component gets a different key.\n",
    "    \n",
    "OK, let's try to do that. We'll define an object called `ModelStage` which holds the three pieces of information required to define each model stage. Then we'll define a `model_spec` that defines all the stages of our model, in these terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class ModelStage(eqx.Module):\n",
    "    component: Callable\n",
    "    where_input: Callable\n",
    "    where_state: Callable\n",
    "\n",
    "\n",
    "model_spec = dict({\n",
    "    'update_feedback': ModelStage(\n",
    "        # See explanation below for why we define this as a lambda!\n",
    "        func=lambda self: self.feedback_channel,  \n",
    "        where_input=lambda input, state: self.where_feedback(state),\n",
    "        where_state=lambda state: state.feedback,  \n",
    "    ),\n",
    "    'net_step': ModelStage(\n",
    "        func=lambda self: self.net,\n",
    "        where_input=lambda input, state: (input, state.feedback.output),\n",
    "        where_state=lambda state: state.net,                \n",
    "    ),\n",
    "    'mechanics_step': ModelStage(\n",
    "        func=lambda self: self.mechanics,\n",
    "        where_input=lambda input, state: state.net.output,\n",
    "        where_state=lambda state: state.mechanics,\n",
    "    ),\n",
    "})       \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! NOTE   \n",
    "    Each of the entries in `ModelStage` is a function, which we define with `lambda`. \n",
    "    \n",
    "    For `where_input` and `where_state`, this is similar to what we've seen in earlier examples. For example, given the `input` and `state` passed to `__call__`, `where_input` is a function that selects which parts will be passed to the component of the current model stage. \n",
    "    \n",
    "    Why do we define `func` as `#!py lambda self: self.something` rather than just `#!py self.something`? It's to make sure that the reference to the component \"stays fresh\". If this doesn't make sense to you, don't worry about it at this point. Just remember that if you write your own staged models, you will need to write your `model_spec` this way.\n",
    "\n",
    "In order to insert interventions at arbitrary points, here's what we'll do: \n",
    "\n",
    "1. define `model_spec` as an attribute of `SimpleFeedback`;\n",
    "2. define `__call__` so that it calls each of the entries in `model_spec`, passing them their respective input and state, and using their return value to update the model state.    \n",
    "\n",
    "    !!! Warning \"\"    \n",
    "    \n",
    "        Importantly, the way we define `__call__` will no longer allow our model stages to assign, or refer, to intermediate variables like `feedback_state`. This is why in the `model_spec` we just defined, the input to `self.net` includes `state.feedback.output`, where previously we had passed `feedback_state.output`.\n",
    "        \n",
    "        In our new `__call__`, we'll update `state` *immediately* after each stage, rather than assigning to intermediate variables and then finally constructing a new `SimpleFeedbackState`. Thus any changes one stage makes, can be passed to subsequent states by referring to `state` itself, like we do with `state.feedback.output`.\n",
    "        \n",
    "3. give `SimpleFeedback` a new attribute `intervenors`, where we can insert additional components that intervene on the model's state, *given the name of the model stage they should be applied before*. For example, if this attribute is set to `{'mechanics_step': some_intervention}` then `some_intervention` would be called *immediately before* `self.mechanics` is called.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class SimpleFeedback(eqx.Module):\n",
    "    net: eqx.Module  \n",
    "    mechanics: Mechanics \n",
    "    feedback_channel: Channel\n",
    "    where_feedback: Callable[[SimpleFeedbackState], PyTree] = \\\n",
    "        lambda state: state.mechanics.plant.skeleton\n",
    "    intervenors: dict[str, eqx.Module]    \n",
    "    \n",
    "    @property\n",
    "    def model_spec(self):\n",
    "        return dict({\n",
    "            'update_feedback': ModelStage(\n",
    "                func=lambda self: self.feedback_channel,  \n",
    "                where_input=lambda input, state: self.where_feedback(state),\n",
    "                where_state=lambda state: state.feedback,  \n",
    "            ),\n",
    "            'net_step': ModelStage(\n",
    "                func=lambda self: self.net,\n",
    "                where_input=lambda input, state: (input, state.feedback.output),\n",
    "                where_state=lambda state: state.net,                \n",
    "            ),\n",
    "            'mechanics_step': ModelStage(\n",
    "                func=lambda self: self.mechanics,\n",
    "                where_input=lambda input, state: state.net.output,\n",
    "                where_state=lambda state: state.mechanics,\n",
    "            ),\n",
    "        })    \n",
    "    \n",
    "    def __call__(\n",
    "        self, \n",
    "        input: PyTree[Array],  \n",
    "        state: SimpleFeedbackState, \n",
    "        key: PRNGKeyArray,\n",
    "    ) -> SimpleFeedbackState:\n",
    "    \n",
    "        # Get a different key for each stage of the model.\n",
    "        keys = jr.split(key, len(self.model_spec))\n",
    "        \n",
    "        # Loop through the model stages, pairing them with their keys.\n",
    "        for (label, stage), key_stage in zip(self.model_spec.items(), keys):\n",
    "            \n",
    "            # Loop through all intervenors assigned to this model stage.\n",
    "            for intervenor in self.intervenors[label]:\n",
    "                state = intervenor(state)\n",
    "            \n",
    "            # Get the updated part of the state associated with the stage\n",
    "            new_component_state = stage.func(\n",
    "                stage.where_input(input, state),\n",
    "                stage.where_state(state),\n",
    "                key_stage,\n",
    "            )\n",
    "            \n",
    "            # Modify the full model state\n",
    "            state = eqx.tree_at(\n",
    "                stage.where_state,  # Part to modify\n",
    "                state,  # What is modified (full state)\n",
    "                new_component_state,  # New part to insert\n",
    "            )\n",
    "        \n",
    "        return state\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is now structured so that it's possible to [insert interventions](/feedbax/examples/3_intervening/#adding-a-force-field) among its stages, without rewriting the whole thing each time!\n",
    "\n",
    "The way we've defined `__call__` here is quite general. Actually, the real [`feedbax.bodies.SimpleFeedback`][feedbax.bodies.SimpleFeedback] doesn't define `__call__` itself, but inherits it from [`feedbax.AbstractStagedModel`][feedbax.AbstractStagedModel]. Each staged model, including `SimpleFeedback`, just has to define `model_spec` (and a couple of other smaller things)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining models as a sequence of named state operations has some additional advantages, beyond being able to insert interventions among the stages. For one, it makes it easy to [log the details](/feedbax/examples/debugging/#logging-details-of-model-execution) of our model stages as they are executed, which is useful for debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty printing of model stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another advantage of staged models is that it's easy to print out a tree of operations, in the sequence they are performed by the model.\n",
    "\n",
    "Feedbax provides the function [`pprint_model_spec`](feedbax.pprint_model_spec) for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update_feedback: MultiModel\n",
      "nn_step: SimpleStagedNetwork\n",
      "  hidden: GRUCell\n",
      "  readout: SimpleStagedNetwork._output\n",
      "mechanics_step: Mechanics\n",
      "  convert_effector_force: PointMass.update_state_given_effector_force\n",
      "  statics_step: DirectForceInput\n",
      "    clip_skeleton_state: DirectForceInput._clip_state\n",
      "  dynamics_step: Mechanics._dynamics_step\n",
      "  get_effector: PointMass.effector\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "from feedbax import pprint_model_spec\n",
    "from feedbax.xabdeef import point_mass_nn_simple_reaches\n",
    "\n",
    "context = point_mass_nn_simple_reaches(key=jax.random.PRNGKey(0))\n",
    "\n",
    "pprint_model_spec(context.model.step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line corresponds to a call to a model component. When the model component is also a staged model, the stages of that component are indented on the lines that follow.\n",
    "\n",
    "For example, the `\"nn_step\"` stage of `SimpleFeedback` is a call to `self.net`, which in this case is a `SimpleStagedNetwork`, which is also a subclass of `AbstractStagedModel`, and in this case has a stage named `\"hidden\"` that calls `equinox.nn.GRUCell`, followed by a stage `\"readout\"` that calls the method `_output` of the `SimpleStagedNetwork` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a staged model\n",
    "\n",
    "What components are needed.\n",
    "\n",
    "Example: similar to `SimpleFeedback`, but with two neural networks with a `Channel` between them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using simple functions as stages\n",
    "\n",
    "i.e. that modify part of the state, but may not have associated state\n",
    "a\n",
    "Wrappers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using non-staged components \n",
    "\n",
    "- Using existing neural networks as controllers \n",
    "    - And the downside (intervenors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
