{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From automatic to manual\n",
    "\n",
    "In the [previous example](/feedbax/examples/0_train_simple), almost everything was pre-built and we didn't get to see how the model was put together. Let's rebuild the same model, but more explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll explicitly define the values of some parameters, where last time we had just implicitly accepted the default values defined in the pre-built model/task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = 1.0  # Mass of the point mass\n",
    "n_steps = 100  # Number of time steps per trial\n",
    "dt = 0.05  # Duration of a time step\n",
    "feedback_delay_steps = 0  # Number of time steps to delay the feedback\n",
    "feedback_noise_std = 0.1  # Standard deviation of Gaussian noise added to sensory feedback\n",
    "workspace = ((-1., -1.),  # Workspace bounds ((x_min, y_min), (x_max, y_max)\n",
    "             (1., 1.))\n",
    "hidden_size  = 50  # Number of units in the hidden layer of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use `jax.random.split` to get several random keys we can use for different purposes as we go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 18:50:16.778053: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_UNKNOWN: unknown error\n",
      "CUDA backend failed to initialize: INTERNAL: no supported devices found for platform CUDA (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import jax.random as jr\n",
    "\n",
    "seed = 0 \n",
    "key = jr.PRNGKey(seed)  # This is the parent key\n",
    "\n",
    "# Split into three different keys for initialisation, training, and evaluation\n",
    "key_init, key_train, key_eval = jr.split(key, 3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairing of a pre-built model with a different task\n",
    "\n",
    "Last time we saw that `feedbax.xabdeef` provides some pre-built pairings of tasks and models, which can be constructed with a single line of code, then trained immediately.\n",
    "\n",
    "However, it also provides pre-built models that aren't paired with tasks. For example, we can import `point_mass_nn` and use it to construct the same model as `point_mass_nn_simple_reaches` did—but just the model.\n",
    "\n",
    "We'll use the same task as before, but construct it explicitly: `SimpleReaches` combined with the pre-built loss function `simple_reach_loss`. \n",
    "\n",
    "!!! Warning \"\"    \n",
    "    We have to construct the task before the model, since the structure of the model—the number of inputs to the neural network—depends on the kind of information the task will send it—in this case, the goal it should currently be reaching for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mll/.miniforge3/envs/fx/lib/python3.11/site-packages/diffrax/adjoint.py:665: UserWarning: As of Equinox 0.10.7, `equinox.filter_custom_vjp.defvjp` is deprecated in favour of `.def_fwd` and `.def_bwd`. This new API supports symbolic zeros, which allow for more efficient autodifferentiation rules. In particular:\n",
      "- the fwd and bwd functions take an extra `perturbed` argument, which     indicates which primals actually need a gradient. You can use this     to skip computing the gradient for any unperturbed value. (You can     also safely just ignore this if you wish.)\n",
      "- `None` was previously passed to indicate a symbolic zero gradient for     all objects that weren't inexact arrays, but all inexact arrays     always had an array-valued gradient. Now, `None` may also be passed     to indicate that an inexact array has a symbolic zero gradient.\n",
      "  _loop_backsolve.defvjp(_loop_backsolve_fwd, _loop_backsolve_bwd)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'workspace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeedbax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxabdeef\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple_reach_loss\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeedbax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxabdeef\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m point_mass_nn\n\u001b[1;32m      7\u001b[0m task \u001b[38;5;241m=\u001b[39m SimpleReaches(\n\u001b[1;32m      8\u001b[0m     loss_func\u001b[38;5;241m=\u001b[39msimple_reach_loss(),\n\u001b[0;32m----> 9\u001b[0m     workspace\u001b[38;5;241m=\u001b[39m\u001b[43mworkspace\u001b[49m, \n\u001b[1;32m     10\u001b[0m     n_steps\u001b[38;5;241m=\u001b[39mn_steps,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m point_mass_nn(\n\u001b[1;32m     14\u001b[0m     task,\n\u001b[1;32m     15\u001b[0m     dt\u001b[38;5;241m=\u001b[39mdt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     key\u001b[38;5;241m=\u001b[39mkey_init,\n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'workspace' is not defined"
     ]
    }
   ],
   "source": [
    "from feedbax.task import SimpleReaches\n",
    "\n",
    "from feedbax.xabdeef.losses import simple_reach_loss\n",
    "from feedbax.xabdeef.models import point_mass_nn\n",
    "\n",
    "\n",
    "task = SimpleReaches(\n",
    "    loss_func=simple_reach_loss(),\n",
    "    workspace=workspace, \n",
    "    n_steps=n_steps,\n",
    ")\n",
    "\n",
    "model = point_mass_nn(\n",
    "    task,\n",
    "    dt=dt,\n",
    "    mass=mass,\n",
    "    hidden_size=hidden_size, \n",
    "    n_steps=n_steps,\n",
    "    feedback_delay_steps=feedback_delay_steps,\n",
    "    feedback_noise_std=feedback_noise_std,\n",
    "    key=key_init,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we could construct a `TaskTrainer` and use it to train the model on the task, but let's go just one more level deeper first and define exactly the same model without using a pre-built function from `feedbax.xabdeef`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model ourselves using core Feedbax\n",
    "\n",
    "Let's rewrite the function `point_mass_nn` right here, and see how it's built out of Feedbax components. First we'll show the whole thing, and then we'll go through it step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "\n",
    "from feedbax.bodies import SimpleFeedback\n",
    "from feedbax.iterate import Iterator\n",
    "from feedbax.mechanics.mechanics import Mechanics\n",
    "from feedbax.mechanics.plant import DirectForceInput\n",
    "from feedbax.mechanics.skeleton.pointmass import PointMass\n",
    "from feedbax.nn import SimpleStagedNetwork\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    task,\n",
    "    dt: float = 0.05, \n",
    "    mass: float = 1., \n",
    "    hidden_size: int = 50, \n",
    "    n_steps: int = 100, \n",
    "    feedback_delay: int = 0,\n",
    "    feedback_noise_std: float = 0.0,\n",
    "    *,  # This asterisk forces us to pass `key` as a keyword argument\n",
    "    key,\n",
    "):   \n",
    "    key1, key2 = jr.split(key)  # 1\n",
    "\n",
    "    plant = DirectForceInput(PointMass(mass=mass))  # 2\n",
    "    mechanics = Mechanics(plant, dt)  # 3\n",
    "    \n",
    "    feedback_spec = dict(  # 4\n",
    "        where=lambda state: (\n",
    "            state.effector.pos,\n",
    "            state.effector.vel,\n",
    "        ),\n",
    "        delay=feedback_delay,\n",
    "        noise_std=feedback_noise_std,\n",
    "    )\n",
    "    \n",
    "    # Determine the network input size automatically\n",
    "    input_size = SimpleFeedback.get_nn_input_size(  # 5\n",
    "        task, mechanics, feedback_spec\n",
    "    )\n",
    "    \n",
    "    net = SimpleStagedNetwork(  # 6\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        out_size=plant.input_size,\n",
    "        noise_std=0.0,\n",
    "        key=key1\n",
    "    )\n",
    "    \n",
    "    body = SimpleFeedback(net, mechanics, feedback_spec=feedback_spec, key=key2)  # 7\n",
    "    \n",
    "    model = Iterator(body, n_steps)  # 8\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "1. We only pass a single key to the function. The function needs two keys though, which it splits for itself.\n",
    "2. Our mechanical model—or *plant*—is a point mass. We'll move it by directly applying force. In more complex models, the input to the mechanical model can be signals to simulated muscles, in which case the forces aren't supplied directly, but produced by the muscles contracting.\n",
    "3. Our plant model describes *continuous* dynamics. We need to discretize it, and associate it with a numerical solver of differential equations. We do this by wrapping it in `Mechanics`, with a value for the time step duration.\n",
    "4. Define which parts of the mechanical state will be available to the neural network as sensory feedback. Use a function `where`, which when passed the `state` associated with `mechanics`, will return the parts of that state we want to be part of the feedback. In the case of a point mass, we use the position and velocity of the point mass itself. Feedback may be noisy or delayed, and we also define values for those parameters at this point.\n",
    "5. Figure out how many inputs the neural network will need. This depends on the information that the task will provide to the network, but also the kind of sensory feedback. The method `get_nn_input_size` figures this out for us.\n",
    "6. Construct our neural network model.\n",
    "7. Construct a model in which our neural network sends commands to our mechanical model, and gets feedback in return.\n",
    "8. All of the preceding steps define a single time step of the model. We wrap this into an object that loops the model for a given number of timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our function, we can now construct a model just like we did with `point_mass_nn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleIterator(\n",
       "  step=SimpleFeedback(\n",
       "    net=SimpleNetwork(\n",
       "      out_size=2,\n",
       "      hidden=GRUCell(\n",
       "        weight_ih=f32[150,8],\n",
       "        weight_hh=f32[150,50],\n",
       "        bias=f32[150],\n",
       "        bias_n=f32[50],\n",
       "        input_size=8,\n",
       "        hidden_size=50,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      hidden_size=50,\n",
       "      noise_std=None,\n",
       "      hidden_nonlinearity=None,\n",
       "      encoder=None,\n",
       "      encoding_size=None,\n",
       "      readout=Linear(\n",
       "        weight=f32[2,50],\n",
       "        bias=f32[2],\n",
       "        in_features=50,\n",
       "        out_features=2,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      out_nonlinearity=<function <lambda>>,\n",
       "      intervenors={'hidden': [], 'readout': []}\n",
       "    ),\n",
       "    mechanics=Mechanics(\n",
       "      plant=SimplePlant(\n",
       "        skeleton=PointMass(mass=1.0),\n",
       "        clip_states=True,\n",
       "        intervenors={'clip_skeleton_state': []},\n",
       "        muscle_model=None\n",
       "      ),\n",
       "      dt=0.05,\n",
       "      solver=Euler(),\n",
       "      intervenors={\n",
       "        'convert_effector_force':\n",
       "        [],\n",
       "        'statics_step':\n",
       "        [],\n",
       "        'dynamics_step':\n",
       "        [],\n",
       "        'get_effector':\n",
       "        []\n",
       "      }\n",
       "    ),\n",
       "    feedback_channels=[\n",
       "      Channel(\n",
       "        delay=1,\n",
       "        noise_std=0.1,\n",
       "        init_value=nan,\n",
       "        input_proto=(f32[2], f32[2]),\n",
       "        intervenors={'update_queue': [], 'add_noise': []}\n",
       "      )\n",
       "    ],\n",
       "    feedback_specs=[\n",
       "      ChannelSpec(where=<function <lambda>>, delay=0, noise_std=0.1)\n",
       "    ],\n",
       "    intervenors={'update_feedback': [], 'nn_step': [], 'mechanics_step': []}\n",
       "  ),\n",
       "  n_steps=100\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(\n",
    "    task,\n",
    "    dt=dt,\n",
    "    hidden_size=hidden_size,\n",
    "    n_steps=n_steps,\n",
    "    feedback_delay=feedback_delay_steps,\n",
    "    feedback_noise_std=feedback_noise_std,\n",
    "    key=key_init, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the model's tree structure\n",
    "\n",
    "Now's a good time to take a look at the structure of the model we've built. Since all Feedbax models are [Equinox](/feedbax/examples/pytrees#equinox) modules, we can simply print them and the output is a nice tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleIterator(\n",
       "  step=SimpleFeedback(\n",
       "    net=SimpleNetwork(\n",
       "      out_size=2,\n",
       "      hidden=GRUCell(\n",
       "        weight_ih=f32[150,8],\n",
       "        weight_hh=f32[150,50],\n",
       "        bias=f32[150],\n",
       "        bias_n=f32[50],\n",
       "        input_size=8,\n",
       "        hidden_size=50,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      hidden_size=50,\n",
       "      noise_std=None,\n",
       "      hidden_nonlinearity=None,\n",
       "      encoder=None,\n",
       "      encoding_size=None,\n",
       "      readout=Linear(\n",
       "        weight=f32[2,50],\n",
       "        bias=f32[2],\n",
       "        in_features=50,\n",
       "        out_features=2,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      out_nonlinearity=<function <lambda>>,\n",
       "      intervenors={'hidden': [], 'readout': []}\n",
       "    ),\n",
       "    mechanics=Mechanics(\n",
       "      plant=SimplePlant(\n",
       "        skeleton=PointMass(mass=1.0),\n",
       "        clip_states=True,\n",
       "        intervenors={'clip_skeleton_state': []},\n",
       "        muscle_model=None\n",
       "      ),\n",
       "      dt=0.05,\n",
       "      solver=Euler(),\n",
       "      intervenors={\n",
       "        'convert_effector_force':\n",
       "        [],\n",
       "        'statics_step':\n",
       "        [],\n",
       "        'dynamics_step':\n",
       "        [],\n",
       "        'get_effector':\n",
       "        []\n",
       "      }\n",
       "    ),\n",
       "    feedback_channels=[\n",
       "      Channel(\n",
       "        delay=1,\n",
       "        noise_std=0.1,\n",
       "        init_value=nan,\n",
       "        input_proto=(f32[2], f32[2]),\n",
       "        intervenors={'update_queue': [], 'add_noise': []}\n",
       "      )\n",
       "    ],\n",
       "    feedback_specs=[\n",
       "      ChannelSpec(where=<function <lambda>>, delay=0, noise_std=0.1)\n",
       "    ],\n",
       "    intervenors={'update_feedback': [], 'nn_step': [], 'mechanics_step': []}\n",
       "  ),\n",
       "  n_steps=100\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Note \"\"\n",
    "    The notation `f32[150,8]` indicates a JAX array of shape `(150, 8)` filled with `float32` values.\n",
    "\n",
    "This tree reflects how we defined our model. We can see that:\n",
    "\n",
    "- The topmost level is an `Iterator`, which is responsible for looping over a model step for `n_steps`.\n",
    "- The model step is an instance of `SimpleFeedback`, composed of a `SimpleStagedNetwork` which sends commands to, and receives feedback from, a `Mechanics` instance\n",
    "- The `Mechanics` instance contains a plant `DirectForceInput` which wraps a `PointMass` \"skeleton\".\n",
    "\n",
    "!!! Note \"\"\n",
    "    Importantly, the tree does not show us *how* each part of the model performs its computations, including how it calls its components. This representation only shows us which parts of the model *contain* which other parts or parameters.\n",
    "\n",
    "We can also see several things that were not obvious from the way we defined our model:\n",
    "\n",
    "- `SimpleStagedNetwork` consists of a `GRUCell` containing arrays of weights, as well as a `Linear` readout with its own weights. However, `encoder=None` since by default the network object is constructed without a separate layer for encoding its inputs. All of these aspects can be controlled by different arguments we could have passed to `SimpleStagedNetwork`.\n",
    "- `Mechanics` is using the default `Euler` solver. Usually this is sufficient, but in some cases it might be more accurate to use one of the higher-order solvers provided by `diffrax`, by passing it as the `solver` argument when wrapping our plant in `Mechanics`.\n",
    "- Part of the tree is called `feedback_channels`, and it contains a list with one `Channel` in it. This channel was constructed by `SimpleFeedback`, based on the `feedback_spec` we passed it. It's easy to [ask](#another-example) for multiple feedback channels with different delays and noise. \n",
    "- Each inner level of the model has a dictionary `intervenors` which contains a bunch of empty lists. Interventions are a powerful feature of Feedbax that we'll check out in the next example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We need to construct a `TaskTrainer`. In the first example this [was managed](/feedbax/examples/0_train_simple/#training-the-model) for us automatically. \n",
    "\n",
    "We can explicitly tell the trainer to use the Adam optimizer, or any other optimizer [provided by Optax](https://optax.readthedocs.io/en/latest/api/optimizers.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "from feedbax.train import TaskTrainer\n",
    "\n",
    "\n",
    "trainer = TaskTrainer(\n",
    "    optimizer=optax.adam(learning_rate=1e-2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train our model to perform the task. \n",
    "\n",
    "### Selecting part of the model to train\n",
    "\n",
    "We'll be explicit about which part of the model we want to train:\n",
    "\n",
    "- All the arrays inside the `GRUCell` layer, which is located at `model.step.net.hidden`, as seen in the printout of the model from earlier;\n",
    "- All the arrays inside of the `Linear` readout layer at `model.step.net.readout`. \n",
    "\n",
    "We write a `lambda` function that the trainer will use to pick out these parts of the model. This is similar to how we wrote a function to pick out the parts of the state to send as sensory feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_train = lambda model: (\n",
    "    model.step.net.hidden,\n",
    "    model.step.net.readout,\n",
    ")\n",
    "\n",
    "# Train the model on the task!\n",
    "model, train_history = trainer(\n",
    "    task=task, \n",
    "    model=model,\n",
    "    n_batches=2000, \n",
    "    batch_size=250, \n",
    "    log_step=200,  # Print out the loss every 200 batches\n",
    "    where_train=where_train,\n",
    "    key=key_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, examining the model tree reveals that `model.step.net.hidden` and `model.step.net.readout` contain all of the JAX arrays inside of `model.step.net` that could even be trained in this case. So we could have written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_train = lambda model: model.step.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and nothing would have changed. Since Feedbax is based on JAX/Equinox, we're pretty flexible in how we can specify parts of models or states.\n",
    "\n",
    "Use of `lambda` is common in Feedbax. Remember that `lambda` is merely a convenient way of defining a function in-line. It would also would have made no difference if we had written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_train(model):\n",
    "    return model.step.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State structure\n",
    "\n",
    "Similarly to Feedbax models, the states operated on (and returned by) those models are also based on `equinox.Module` and have a nice tree representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = task.eval(model, key=jr.PRNGKey(2))\n",
    "\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tree does not show us *how* each part of the state was altered. It only shows us the structure of the data that may be operated on by the different parts of the model. \n",
    "\n",
    "Of course, there is some overlap between the levels in `model` and the levels in `states`, because certain parts of the state are associated with certain components in the model. For example, `Mechanics` expects to be a passed a `MechanicsState` object to work on, and (looking at the state tree) this object can be found inside the `SimpleFeedbackState` object, like how `Mechanics` is a component of `SimpleFeedback`.\n",
    "\n",
    "TODO: Printing the structure of a state PyTree without instantiating it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example\n",
    "\n",
    "What if we want to build a model where the network controls an arm with two rotational joints (think: double pendulum) by directly applying torques, instead of controlling a point mass by directly applying forces?\n",
    "\n",
    "Unlike with the point mass, in this case there's a difference between \n",
    "\n",
    "1. the state of the effector—the end of the arm, which is the part that needs to reach the target;\n",
    "2. the intrinsic state of the arm—its joint angles and angular velocities.\n",
    "\n",
    "We want to treat these as two kinds of feedback: the joint information as fast \"proprioceptive\" feedback, and knowledge of the location of the end of the arm as slower \"visual\" feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 21:03:04.650674: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_UNKNOWN: unknown error\n",
      "CUDA backend failed to initialize: INTERNAL: no supported devices found for platform CUDA (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from feedbax.mechanics.skeleton.arm import TwoLink\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    task,\n",
    "    key=None,\n",
    "    dt=0.05, \n",
    "    hidden_size=50, \n",
    "    n_steps=50, \n",
    "    proprioception_delay=3,\n",
    "    vision_delay=5,\n",
    "):\n",
    "    if key is None:\n",
    "        # in case we just want a skeleton model, e.g. for deserializing\n",
    "        key = jr.PRNGKey(0)\n",
    "\n",
    "    key1, key2, key3 = jr.split(key, 3)\n",
    "\n",
    "    plant = DirectForceInput(TwoLink())  # 1\n",
    "    mechanics = Mechanics(plant, dt)\n",
    "    \n",
    "    feedback_spec = dict(  # 2\n",
    "        proprioception=dict(  # We can label this however we like.\n",
    "            where=lambda state: (\n",
    "                state.skeleton.angle,  # joint angles \n",
    "                state.skeleton.d_angle,  # angular velocities\n",
    "            ),\n",
    "            delay=proprioception_delay,\n",
    "            noise_std=feedback_noise_std,\n",
    "        ),\n",
    "        vision=dict(\n",
    "            where=lambda state: (\n",
    "                state.effector.pos,  # position of the end of the arm\n",
    "                state.effector.vel,  # velocity of the end of the arm\n",
    "            ),\n",
    "            delay=vision_delay,            \n",
    "            noise_std=feedback_noise_std,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    input_size = SimpleFeedback.get_nn_input_size(\n",
    "        task, mechanics, feedback_spec\n",
    "    )\n",
    "\n",
    "    net = SimpleStagedNetwork(\n",
    "        input_size, \n",
    "        hidden_size, \n",
    "        out_size=mechanics.plant.input_size,\n",
    "        key=key1,\n",
    "    )\n",
    "\n",
    "    body = SimpleFeedback(\n",
    "        net, \n",
    "        mechanics, \n",
    "        feedback_spec=feedback_spec,\n",
    "        key=key3,\n",
    "    )\n",
    "    \n",
    "    return Iterator(body, n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a couple of things are different here:\n",
    "\n",
    "1. Our plant is now based on a two-link arm model `TwoLink`, which is directly controlled by torques, rather than a `PointMass` which was directly controlled by linear forces.\n",
    "2. We now specify two different feedback channels with different delays\n",
    "\n",
    "What does the structure of this model look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(task, key=key_init)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `feedback_channels` matches the structure of the `feedback_spec` we specified.\n",
    "\n",
    "We can train this model more or less the way we did for the point mass. Though, we might need to adjust the cost function or the learning rate to get it to converge on a solution efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
