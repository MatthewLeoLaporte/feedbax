{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluating multiple models in parallel\n",
    "\n",
    "Often we need to train multiple copies of the same model in parallel. This is easy in Feedbax, thanks to automatic vectorization with `jax.vmap`.\n",
    "\n",
    "!!! NOTE     \n",
    "    TODO.\n",
    "    Training model replicates is handled automatically if you're using a pre-built model-task pairing. If you want to train 3 replicates, pass `n_replicates=3` \n",
    "\n",
    "Let's see an example of training multiple replicates of the same model, that differ only in terms of their random initializations. We'll start with a function that builds our model, like the one we defined in an earlier [example](/feedbax/examples/1_train/#building-the-model-ourselves-using-core-feedbax)\n",
    "\n",
    "TODO: just use `point_mass_nn`, and mention that we could also write our own `get_model` as in 1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "\n",
    "from feedbax.bodies import SimpleFeedback\n",
    "from feedbax.iterate import Iterator\n",
    "from feedbax.mechanics.mechanics import Mechanics\n",
    "from feedbax.mechanics.plant import DirectForceInput\n",
    "from feedbax.mechanics.skeleton.pointmass import PointMass\n",
    "from feedbax.networks import SimpleStagedNetwork\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    task,\n",
    "    dt: float = 0.05, \n",
    "    mass: float = 1., \n",
    "    hidden_size: int = 50, \n",
    "    n_steps: int = 100, \n",
    "    *,  \n",
    "    key=None,\n",
    "):   \n",
    "    key1, key2 = jax.random.split(key)\n",
    "\n",
    "    plant = DirectForceInput(PointMass(mass=mass))\n",
    "    mechanics = Mechanics(plant, dt)\n",
    "    \n",
    "    feedback_spec = dict(\n",
    "        where=lambda state: (\n",
    "            state.effector.pos,\n",
    "            state.effector.vel,\n",
    "        ),\n",
    "        delay=0,\n",
    "        noise_std=0.0,\n",
    "    )\n",
    "    \n",
    "    # Determine the network input size automatically\n",
    "    input_size = SimpleFeedback.get_nn_input_size(\n",
    "        task, mechanics, feedback_spec\n",
    "    )\n",
    "    \n",
    "    net = SimpleStagedNetwork(\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        hidden_type=eqx.nn.GRUCell,\n",
    "        out_size=plant.input_size,\n",
    "        key=key1\n",
    "    )\n",
    "    \n",
    "    body = SimpleFeedback(net, mechanics, feedback_spec=feedback_spec, key=key2)\n",
    "    \n",
    "    return Iterator(body, n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need a task to train our models on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedbax.task import SimpleReaches\n",
    "\n",
    "from feedbax.xabdeef.losses import simple_reach_loss\n",
    "\n",
    "\n",
    "task = SimpleReaches(\n",
    "    loss_func=simple_reach_loss(),\n",
    "    workspace=((-1., -1.),  # ((x_min, y_min), (x_max, y_max))\n",
    "               (1., 1.)), \n",
    "    n_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could build a single model, like we've done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_init, key_train, key_eval = jax.random.split(jax.random.PRNGKey(0), 3)\n",
    "\n",
    "model = get_model(task, key=key_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build $N$ replicates of the model, we need to:\n",
    "\n",
    "1) Get a different random key for each of the model replicates, so they'll be initialized differently.\n",
    "2) Partially evaluate `get_model` so that it's only a function of the random key. In other words, we'll pass all the arguments that will be the same across all model replicates, leaving only the random key left to be passed.  \n",
    "3) Use `jax.vmap` obtain a vectorized version of the partially evaluated `get_model`, then pass it all the keys at once, to obtain all the model replicates at once.\n",
    "\n",
    "Feedbax provides the function `get_ensemble` to perform these steps. We could just import it---`from feedbax import get_ensemble`---but let's see what the source looks like, and rename a couple of variables to match the current situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "from functools import partial\n",
    "import inspect\n",
    "\n",
    "def get_ensemble(\n",
    "    get_model: Callable, \n",
    "    n_replicates: int, \n",
    "    *args, \n",
    "    key: jax.Array,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"Helper to vmap model generation over a set of random keys.\"\"\"\n",
    "    keys = jax.random.split(key, n_replicates)\n",
    "    get_model_ = partial(get_model, *args, **kwargs)\n",
    "    print(inspect.signature(get_model_).parameters)\n",
    "    return eqx.filter_vmap(get_model_)(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! NOTE    \n",
    "    If you run into problems with `jax.vmap`, try using Equinox's `filter_vmap` as we've done above. It does the same thing, but a little more intelligently.\n",
    "    \n",
    "Now, let's get 5 model replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_model() takes from 1 to 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# task,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# dt: float = 0.05, \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# mass: float = 1., \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# *,  \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# key,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeedbax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ensemble\n\u001b[0;32m---> 13\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43mget_ensemble\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_replicates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/main/10 Projects/10 PhD/20 Feedbax/feedbax/feedbax/model.py:199\u001b[0m, in \u001b[0;36mget_ensemble\u001b[0;34m(get_func, n_ensemble, key, *args)\u001b[0m\n\u001b[1;32m    197\u001b[0m keys \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39msplit(key, n_ensemble)\n\u001b[1;32m    198\u001b[0m get_func_ \u001b[38;5;241m=\u001b[39m partial(get_func, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meqx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_vmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_func_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.miniforge3/envs/fx/lib/python3.11/site-packages/equinox/_vmap_pmap.py:219\u001b[0m, in \u001b[0;36m_VmapWrapper.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot resolve batch dimension. Non-`None` `out_axes` requires \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither `in_axes` or `axis_size` to be not `None`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     vmapd, static \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fun_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43min_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_axis_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_axis_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vmapkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m nonvmapd, out_axes \u001b[38;5;241m=\u001b[39m static\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m jtu\u001b[38;5;241m.\u001b[39mtree_structure(vmapd) \u001b[38;5;241m==\u001b[39m jtu\u001b[38;5;241m.\u001b[39mtree_structure(out_axes)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.miniforge3/envs/fx/lib/python3.11/site-packages/equinox/_vmap_pmap.py:204\u001b[0m, in \u001b[0;36m_VmapWrapper.__call__.<locals>._fun_wrapper\u001b[0;34m(_dynamic_args)\u001b[0m\n\u001b[1;32m    202\u001b[0m _main \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mfind_top_trace(jtu\u001b[38;5;241m.\u001b[39mtree_leaves(_dynamic_args))\u001b[38;5;241m.\u001b[39mmain\n\u001b[1;32m    203\u001b[0m _args \u001b[38;5;241m=\u001b[39m combine(_dynamic_args, static_args)\n\u001b[0;32m--> 204\u001b[0m _out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m _out_axes \u001b[38;5;241m=\u001b[39m _bind_main(_main, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_axes)\n\u001b[1;32m    206\u001b[0m _out_axes \u001b[38;5;241m=\u001b[39m _resolve_axes(_out, _out_axes)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_model() takes from 1 to 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "n_replicates = 5\n",
    "\n",
    "# task,\n",
    "# dt: float = 0.05, \n",
    "# mass: float = 1., \n",
    "# hidden_size: int = 50, \n",
    "# n_steps: int = 100, \n",
    "# *,  \n",
    "# key,\n",
    "\n",
    "from feedbax.model import get_ensemble\n",
    "\n",
    "models = get_ensemble(\n",
    "    get_model, \n",
    "    n_replicates, \n",
    "    task, \n",
    "    0.05,\n",
    "    1.,\n",
    "    50,\n",
    "    0.1,\n",
    "    key=key_init,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The replicated models are all stored in a single object. Consider the single model we constructed earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iterator(\n",
       "  step=SimpleFeedback(\n",
       "    net=SimpleStagedNetwork(\n",
       "      out_size=2,\n",
       "      hidden=GRUCell(\n",
       "        weight_ih=f32[150,8],\n",
       "        weight_hh=f32[150,50],\n",
       "        bias=f32[150],\n",
       "        bias_n=f32[50],\n",
       "        input_size=8,\n",
       "        hidden_size=50,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      hidden_size=50,\n",
       "      hidden_noise_std=None,\n",
       "      hidden_nonlinearity=None,\n",
       "      encoder=None,\n",
       "      encoding_size=None,\n",
       "      readout=Linear(\n",
       "        weight=f32[2,50],\n",
       "        bias=f32[2],\n",
       "        in_features=50,\n",
       "        out_features=2,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      out_nonlinearity=<function <lambda>>,\n",
       "      intervenors={'hidden': [], 'readout': []}\n",
       "    ),\n",
       "    mechanics=Mechanics(\n",
       "      plant=DirectForceInput(\n",
       "        skeleton=PointMass(mass=1.0),\n",
       "        clip_states=True,\n",
       "        intervenors={'clip_skeleton_state': []},\n",
       "        muscle_model=None\n",
       "      ),\n",
       "      dt=0.05,\n",
       "      solver=Euler(),\n",
       "      intervenors={\n",
       "        'convert_effector_force':\n",
       "        [],\n",
       "        'statics_step':\n",
       "        [],\n",
       "        'dynamics_step':\n",
       "        [],\n",
       "        'get_effector':\n",
       "        []\n",
       "      }\n",
       "    ),\n",
       "    feedback_channels=[\n",
       "      Channel(\n",
       "        delay=1,\n",
       "        noise_std=0.0,\n",
       "        init_value=nan,\n",
       "        input_proto=(f32[2], f32[2]),\n",
       "        intervenors={'update_queue': [], 'add_noise': []}\n",
       "      )\n",
       "    ],\n",
       "    feedback_specs=[\n",
       "      ChannelSpec(where=<function <lambda>>, delay=0, noise_std=0.0)\n",
       "    ],\n",
       "    intervenors={'update_feedback': [], 'nn_step': [], 'mechanics_step': []}\n",
       "  ),\n",
       "  n_steps=100\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use `vmap` to construct multiple models at once, the result is essentially the same: a single object. However, each parameter in the [PyTree](/feedbax/examples/2_pytrees/) of the model now has a new leading dimension of size 5. \n",
    "\n",
    "This is very nice because it means 1) similar parameters are all stored together, and 2) overhead is kept to a minimum because we don't (say) construct a list with 5 model objects in it, each with their own copies of an identical set of methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train all these models at once, we can pass them to a `TaskTrainer` instance along with the argument `ensembled=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "from feedbax.trainer import TaskTrainer\n",
    "\n",
    "\n",
    "trainer = TaskTrainer(\n",
    "    optimizer=optax.inject_hyperparams(optax.adam)(\n",
    "        learning_rate=1e-2\n",
    "    ),\n",
    "    checkpointing=True,\n",
    ")\n",
    "\n",
    "# not training readout!\n",
    "where_train = lambda model: (\n",
    "    model.step.net.hidden.weight_hh, \n",
    "    model.step.net.hidden.weight_ih, \n",
    "    model.step.net.hidden.bias\n",
    ")\n",
    "\n",
    "models, train_history = trainer(\n",
    "    task=task, \n",
    "    model=models,\n",
    "    ensembled=True,\n",
    "    n_batches=1000, \n",
    "    batch_size=250, \n",
    "    log_step=100,\n",
    "    where_train=where_train,\n",
    "    key=key_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the mean and standard deviation of the loss term histories, across the replicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedbax.plot import plot_mean_losses\n",
    "\n",
    "plot_mean_losses(train_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = task.eval_ensemble(models, n_replicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing a single model out of the ensemble using `tree_get_idx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how to make multiple plots at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
